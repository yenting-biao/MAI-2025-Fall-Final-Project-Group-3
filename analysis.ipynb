{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fde1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a82753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_MAP = {\n",
    "    \"detectable_format:number_bullet_lists\": \"bullet_lists\",\n",
    "    \"length_constraints:number_words\": \"length_constraints\",\n",
    "    \"length_constraints:number_sentences\": \"length_constraints\",\n",
    "    \"length_constraints:number_paragraphs\": \"length_constraints\",\n",
    "    \"keywords:forbidden_words\": \"keywords\",\n",
    "    \"keywords:existence\": \"keywords\",\n",
    "    \"change_case:english_capital\": \"change_case\",\n",
    "    \"change_case:english_lowercase\": \"change_case\",\n",
    "    \"detectable_format:json_format\": \"json_format\",\n",
    "    \"startend:quotation\": \"wrapping\",\n",
    "    \"detectable_format:title\": \"wrapping\",\n",
    "    \"combination:repeat_prompt\": \"startend\",\n",
    "    \"startend:end_checker\": \"startend\",\n",
    "}\n",
    "GROUP_MAP = {k.replace(':', '_'): v for k, v in GROUP_MAP.items()}\n",
    "\n",
    "GROUP_MAP_CEQ = {\n",
    "    \"change_case:english_capital\": \"change_case\",\n",
    "    \"change_case:english_lowercase\": \"change_case\",\n",
    "    \"detectable_format:json_format\": \"json_format\",\n",
    "    \"startend:quotation\": \"wrapping\",\n",
    "    \"detectable_format:title\": \"wrapping\",\n",
    "    \"combination:repeat_prompt\": \"startend\",\n",
    "    \"startend:end_checker\": \"startend\",\n",
    "}\n",
    "GROUP_MAP_CEQ = {k.replace(':', '_'): v for k, v in GROUP_MAP_CEQ.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3481c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule_eval_jsonl(model_name:str, audio_task:str, response_task:str, IF_task:str, data_dir:str=\"model_responses\") -> dict[int, dict[str, Any]]:\n",
    "    IF_task = IF_task.replace(\":\", \"_\")\n",
    "    file_dir = os.path.join(data_dir, model_name, audio_task, response_task, IF_task, \"reports\")\n",
    "    files = os.listdir(file_dir)\n",
    "    files = [f for f in files if f.startswith(\"rule_eval@output_\") and f.endswith(\".jsonl\")]\n",
    "    results = {}\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(file_dir, file_name)\n",
    "        k = file_name.split(\"@output_\")[-1].split(\"-shot\")[0]\n",
    "        k = int(k)\n",
    "        results[k] = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                results[k].append(json.loads(line))\n",
    "    if len(results) != 9:\n",
    "        print(f\"Warning: Expected 9 shot levels, but got {len(results)} in {file_dir}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab31876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDFfromRuleEvalResults(results:dict[int, dict[str, Any]], response_task:str, performance_metric:str) -> pd.DataFrame:\n",
    "    d = {\"IF_task\": [], \"shot_level\": [], \"n\": []}\n",
    "    response_task = response_task.lower()\n",
    "    if response_task == \"creative_writing\":\n",
    "        d[\"if_rate\"] = []\n",
    "    elif response_task == \"close_ended_questions\":\n",
    "        d[\"if_rate_strict\"] = []\n",
    "        d[\"if_rate_loose\"] = []\n",
    "        d[\"mean_performance\"] = []\n",
    "    elif response_task == \"chain_of_thoughts\":\n",
    "        raise NotImplementedError(\"Chain of thoughts not implemented yet.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown response task: {response_task}\")\n",
    "\n",
    "    for k, v in results.items():\n",
    "        for shot_level, evaluations in v.items():\n",
    "            n = len(evaluations)\n",
    "            d[\"n\"].append(n)\n",
    "            d[\"IF_task\"].append(k)\n",
    "            d[\"shot_level\"].append(shot_level)\n",
    "\n",
    "            if response_task == \"creative_writing\":\n",
    "                follow_flags = [eval['follow_all_instructions'] for eval in evaluations]\n",
    "                d[\"if_rate\"].append(np.mean(follow_flags))\n",
    "            elif response_task == \"close_ended_questions\":\n",
    "                performance_scores = [eval[performance_metric] for eval in evaluations] if performance_metric in evaluations[0] else None\n",
    "                strict_follow_flags = [eval['strict_follow_all_instructions'] for eval in evaluations]\n",
    "                loose_follow_flags = [eval['loose_follow_all_instructions'] for eval in evaluations]\n",
    "                mean_performance = np.mean(performance_scores) if performance_scores is not None else None\n",
    "                if_rate_strict = np.mean(strict_follow_flags)\n",
    "                if_rate_loose = np.mean(loose_follow_flags)\n",
    "                d[\"if_rate_strict\"].append(if_rate_strict)\n",
    "                d[\"if_rate_loose\"].append(if_rate_loose)\n",
    "                d[\"mean_performance\"].append(mean_performance)\n",
    "\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a4bbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_name:str, response_task:str=\"closed_ended_questions\", to_csv:bool=True):\n",
    "    response_task = response_task.lower()\n",
    "    d_df = {}\n",
    "    for audio_task, performance_metric in zip([\"ASR\", \"GR\", \"SER\"], [\"wer\", \"answer_correct\", \"answer_correct\"]):\n",
    "        IF_tasks = os.listdir(os.path.join(\"model_responses\", model_name, audio_task, response_task))\n",
    "        IF_tasks = [ft for ft in IF_tasks if ft in GROUP_MAP.keys()]\n",
    "        results = {}\n",
    "        for IF_task in IF_tasks:\n",
    "            results[IF_task] = get_rule_eval_jsonl(model_name, audio_task, response_task, IF_task)\n",
    "        d_df[audio_task] = createDFfromRuleEvalResults(results, response_task, performance_metric)\n",
    "\n",
    "    if to_csv:\n",
    "        for audio_task, df in d_df.items():\n",
    "            fn = os.path.join(\"./analysis\", f\"{model_name}_{audio_task}_{response_task}_summary.csv\")\n",
    "            print(f\"Saving summary to {fn}\")\n",
    "            df.to_csv(fn, index=False)\n",
    "\n",
    "    return d_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedebd3",
   "metadata": {},
   "source": [
    "# close_ended_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ad11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ qwen ------------\n",
      "Saving summary to ./analysis/qwen_ASR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/qwen_GR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/qwen_SER_closed_ended_questions_summary.csv\n",
      "------------ qwen2 ------------\n",
      "Saving summary to ./analysis/qwen2_ASR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/qwen2_GR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/qwen2_SER_closed_ended_questions_summary.csv\n",
      "------------ desta2_5 ------------\n",
      "Saving summary to ./analysis/desta2_5_ASR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/desta2_5_GR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/desta2_5_SER_closed_ended_questions_summary.csv\n",
      "------------ blsp-emo ------------\n",
      "Saving summary to ./analysis/blsp-emo_ASR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/blsp-emo_GR_closed_ended_questions_summary.csv\n",
      "Saving summary to ./analysis/blsp-emo_SER_closed_ended_questions_summary.csv\n"
     ]
    }
   ],
   "source": [
    "response_task = \"closed_ended_questions\"\n",
    "d_df = {}\n",
    "for model_name in [\"qwen\", \"qwen2\", \"desta2_5\", \"blsp-emo\"]:\n",
    "    print(f\"------------ {model_name} ------------\")\n",
    "    d_df[model_name] = eval(model_name, response_task=response_task, to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53607dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving combined summary to ./analysis/summary_ceq.xlsx\n"
     ]
    }
   ],
   "source": [
    "model_order = [\"qwen\", \"qwen2\", \"desta2_5\", \"blsp-emo\"]\n",
    "\n",
    "# put \"other\" last; keep the rest in a deterministic order\n",
    "group_order = []\n",
    "for v in GROUP_MAP_CEQ.values():\n",
    "    if v not in group_order and v != \"other\":\n",
    "        group_order.append(v)\n",
    "\n",
    "df_audio_task = {}\n",
    "fn = os.path.join(\"./analysis\", f\"summary_ceq.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(fn, engine=\"openpyxl\") as writer:\n",
    "    for audio_task in [\"ASR\", \"GR\", \"SER\"]:\n",
    "        dfs = []\n",
    "        for model_name in model_order:\n",
    "            df = d_df[model_name][audio_task].copy()\n",
    "\n",
    "            df[\"model\"] = model_name\n",
    "            df[\"IF_task_group\"] = df[\"IF_task\"].map(GROUP_MAP_CEQ)\n",
    "\n",
    "            df = df[[\n",
    "                \"IF_task_group\", \"IF_task\", \"n\", \"model\",\n",
    "                \"shot_level\", \"if_rate_strict\", \"if_rate_loose\", \"mean_performance\"\n",
    "            ]]\n",
    "            dfs.append(df)\n",
    "\n",
    "        df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # --- ordered categoricals for deterministic sorting ---\n",
    "        # shot_level: if it's numeric, this works; if it's strings like \"0-shot\", see note below\n",
    "        shot_order = sorted(df_all[\"shot_level\"].dropna().unique())\n",
    "        df_all[\"shot_level\"] = pd.Categorical(df_all[\"shot_level\"], categories=shot_order, ordered=True)\n",
    "\n",
    "        df_all[\"IF_task_group\"] = pd.Categorical(df_all[\"IF_task_group\"], categories=group_order, ordered=True)\n",
    "        df_all[\"model\"] = pd.Categorical(df_all[\"model\"], categories=model_order, ordered=True)\n",
    "\n",
    "        df_all_compare_shots = df_all.sort_values(\n",
    "            by=[\"IF_task_group\", \"IF_task\", \"model\"],\n",
    "            ascending=[True, True, True],\n",
    "            kind=\"mergesort\",\n",
    "        )\n",
    "\n",
    "        df_all = df_all.sort_values(\n",
    "            by=[\"shot_level\", \"IF_task_group\", \"IF_task\", \"model\"],\n",
    "            ascending=[True, True, True, True],\n",
    "            kind=\"mergesort\",\n",
    "        )\n",
    "\n",
    "        df_all_grouped = df_all.groupby([\"shot_level\", \"IF_task_group\", \"model\"], observed=False).mean(numeric_only=True).reset_index()\n",
    "        df_all_compare_shots_grouped = df_all_compare_shots.groupby([\"IF_task_group\", \"model\", \"shot_level\"], observed=False).mean(numeric_only=True).reset_index()\n",
    "\n",
    "        df_all.to_excel(writer, sheet_name=audio_task, index=False)\n",
    "        df_all_grouped.to_excel(writer, sheet_name=f\"{audio_task}_grouped\", index=False)\n",
    "        df_all_compare_shots.to_excel(writer, sheet_name=f\"{audio_task}_compare_shots\", index=False)\n",
    "        df_all_compare_shots_grouped.to_excel(writer, sheet_name=f\"{audio_task}_compare_shots_grouped\", index=False)\n",
    "\n",
    "        df_audio_task[audio_task] = df_all\n",
    "        df_audio_task[f\"{audio_task}_grouped\"] = df_all_grouped\n",
    "        df_audio_task[f\"{audio_task}_compare_shots\"] = df_all_compare_shots\n",
    "        df_audio_task[f\"{audio_task}_compare_shots_grouped\"] = df_all_compare_shots_grouped\n",
    "\n",
    "print(f\"Saving combined summary to {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eca12877",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ASR', 'ASR_grouped', 'ASR_compare_shots', 'ASR_compare_shots_grouped', 'GR', 'GR_grouped', 'GR_compare_shots', 'GR_compare_shots_grouped', 'SER', 'SER_grouped', 'SER_compare_shots', 'SER_compare_shots_grouped'])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio_task.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641011b0",
   "metadata": {},
   "source": [
    "# creative_writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac241724",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ qwen ------------\n",
      "Saving summary to ./analysis/qwen_ASR_creative_writing_summary.csv\n",
      "Saving summary to ./analysis/qwen_GR_creative_writing_summary.csv\n",
      "Saving summary to ./analysis/qwen_SER_creative_writing_summary.csv\n",
      "------------ qwen2 ------------\n",
      "Saving summary to ./analysis/qwen2_ASR_creative_writing_summary.csv\n",
      "Saving summary to ./analysis/qwen2_GR_creative_writing_summary.csv\n",
      "Saving summary to ./analysis/qwen2_SER_creative_writing_summary.csv\n"
     ]
    }
   ],
   "source": [
    "response_task = \"creative_writing\"\n",
    "d_df_cw = {}\n",
    "for model_name in [\"qwen\", \"qwen2\"]: #, \"desta2_5\", \"blsp-emo\"]:\n",
    "    print(f\"------------ {model_name} ------------\")\n",
    "    d_df_cw[model_name] = eval(model_name, response_task=response_task, to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1855aae",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IF_task</th>\n",
       "      <th>shot_level</th>\n",
       "      <th>n</th>\n",
       "      <th>if_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>detectable_format_number_bullet_lists</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>keywords_existence</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>keywords_forbidden_words</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>length_constraints_number_paragraphs</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>length_constraints_number_sentences</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>length_constraints_number_words</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  IF_task  shot_level   n   if_rate\n",
       "0   detectable_format_number_bullet_lists           0  24  0.791667\n",
       "1   detectable_format_number_bullet_lists           1  24  0.750000\n",
       "2   detectable_format_number_bullet_lists           2  24  0.833333\n",
       "3   detectable_format_number_bullet_lists           3  24  0.833333\n",
       "4   detectable_format_number_bullet_lists           4  24  0.875000\n",
       "5   detectable_format_number_bullet_lists           5  24  0.916667\n",
       "6   detectable_format_number_bullet_lists           6  24  0.875000\n",
       "7   detectable_format_number_bullet_lists           7  24  0.875000\n",
       "8   detectable_format_number_bullet_lists           8  24  0.875000\n",
       "9                      keywords_existence           0  50  0.820000\n",
       "10                     keywords_existence           1  50  0.780000\n",
       "11                     keywords_existence           2  50  0.780000\n",
       "12                     keywords_existence           3  50  0.700000\n",
       "13                     keywords_existence           4  50  0.780000\n",
       "14                     keywords_existence           5  50  0.720000\n",
       "15                     keywords_existence           6  50  0.720000\n",
       "16                     keywords_existence           7  50  0.740000\n",
       "17                     keywords_existence           8  50  0.680000\n",
       "18               keywords_forbidden_words           0  50  0.680000\n",
       "19               keywords_forbidden_words           1  50  0.900000\n",
       "20               keywords_forbidden_words           2  50  0.900000\n",
       "21               keywords_forbidden_words           3  50  0.920000\n",
       "22               keywords_forbidden_words           4  50  0.920000\n",
       "23               keywords_forbidden_words           5  50  0.940000\n",
       "24               keywords_forbidden_words           6  50  0.900000\n",
       "25               keywords_forbidden_words           7  50  0.900000\n",
       "26               keywords_forbidden_words           8  50  0.940000\n",
       "27   length_constraints_number_paragraphs           0  16  0.187500\n",
       "28   length_constraints_number_paragraphs           1  16  0.062500\n",
       "29   length_constraints_number_paragraphs           2  16  0.125000\n",
       "30   length_constraints_number_paragraphs           3  16  0.250000\n",
       "31   length_constraints_number_paragraphs           4  16  0.125000\n",
       "32   length_constraints_number_paragraphs           5  16  0.250000\n",
       "33   length_constraints_number_paragraphs           6  16  0.187500\n",
       "34   length_constraints_number_paragraphs           7  16  0.125000\n",
       "35   length_constraints_number_paragraphs           8  16  0.187500\n",
       "36    length_constraints_number_sentences           0  32  0.625000\n",
       "37    length_constraints_number_sentences           1  32  0.656250\n",
       "38    length_constraints_number_sentences           2  32  0.875000\n",
       "39    length_constraints_number_sentences           3  32  0.656250\n",
       "40    length_constraints_number_sentences           4  32  0.687500\n",
       "41    length_constraints_number_sentences           5  32  0.718750\n",
       "42    length_constraints_number_sentences           6  32  0.718750\n",
       "43    length_constraints_number_sentences           7  32  0.718750\n",
       "44    length_constraints_number_sentences           8  32  0.656250\n",
       "45        length_constraints_number_words           0  16  0.625000\n",
       "46        length_constraints_number_words           1  16  0.625000\n",
       "47        length_constraints_number_words           2  16  0.687500\n",
       "48        length_constraints_number_words           3  16  0.562500\n",
       "49        length_constraints_number_words           4  16  0.625000\n",
       "50        length_constraints_number_words           5  16  0.562500\n",
       "51        length_constraints_number_words           6  16  0.500000\n",
       "52        length_constraints_number_words           7  16  0.625000\n",
       "53        length_constraints_number_words           8  16  0.562500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_order = [\"qwen\", \"qwen2\", \"desta2_5\", \"blsp-emo\"]\n",
    "\n",
    "# put \"other\" last; keep the rest in a deterministic order\n",
    "group_order = []\n",
    "for v in GROUP_MAP_CEQ.values():\n",
    "    if v not in group_order and v != \"other\":\n",
    "        group_order.append(v)\n",
    "\n",
    "df_audio_task = {}\n",
    "fn = os.path.join(\"./analysis\", f\"summary_ceq.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(fn, engine=\"openpyxl\") as writer:\n",
    "    for audio_task in [\"ASR\", \"GR\", \"SER\"]:\n",
    "        dfs = []\n",
    "        for model_name in model_order:\n",
    "            df = d_df[model_name][audio_task].copy()\n",
    "\n",
    "            df[\"model\"] = model_name\n",
    "            df[\"IF_task_group\"] = df[\"IF_task\"].map(GROUP_MAP_CEQ)\n",
    "\n",
    "            df = df[[\n",
    "                \"IF_task_group\", \"IF_task\", \"n\", \"model\",\n",
    "                \"shot_level\", \"if_rate_strict\", \"if_rate_loose\", \"mean_performance\"\n",
    "            ]]\n",
    "            dfs.append(df)\n",
    "\n",
    "        df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # --- ordered categoricals for deterministic sorting ---\n",
    "        # shot_level: if it's numeric, this works; if it's strings like \"0-shot\", see note below\n",
    "        shot_order = sorted(df_all[\"shot_level\"].dropna().unique())\n",
    "        df_all[\"shot_level\"] = pd.Categorical(df_all[\"shot_level\"], categories=shot_order, ordered=True)\n",
    "\n",
    "        df_all[\"IF_task_group\"] = pd.Categorical(df_all[\"IF_task_group\"], categories=group_order, ordered=True)\n",
    "        df_all[\"model\"] = pd.Categorical(df_all[\"model\"], categories=model_order, ordered=True)\n",
    "\n",
    "        df_all_compare_shots = df_all.sort_values(\n",
    "            by=[\"IF_task_group\", \"IF_task\", \"model\"],\n",
    "            ascending=[True, True, True],\n",
    "            kind=\"mergesort\",\n",
    "        )\n",
    "\n",
    "        df_all = df_all.sort_values(\n",
    "            by=[\"shot_level\", \"IF_task_group\", \"IF_task\", \"model\"],\n",
    "            ascending=[True, True, True, True],\n",
    "            kind=\"mergesort\",\n",
    "        )\n",
    "\n",
    "        df_all_grouped = df_all.groupby([\"shot_level\", \"IF_task_group\", \"model\"], observed=False).mean(numeric_only=True).reset_index()\n",
    "        df_all_compare_shots_grouped = df_all_compare_shots.groupby([\"IF_task_group\", \"model\", \"shot_level\"], observed=False).mean(numeric_only=True).reset_index()\n",
    "\n",
    "        df_all.to_excel(writer, sheet_name=audio_task, index=False)\n",
    "        df_all_grouped.to_excel(writer, sheet_name=f\"{audio_task}_grouped\", index=False)\n",
    "        df_all_compare_shots.to_excel(writer, sheet_name=f\"{audio_task}_compare_shots\", index=False)\n",
    "        df_all_compare_shots_grouped.to_excel(writer, sheet_name=f\"{audio_task}_compare_shots_grouped\", index=False)\n",
    "\n",
    "        df_audio_task[audio_task] = df_all\n",
    "        df_audio_task[f\"{audio_task}_grouped\"] = df_all_grouped\n",
    "        df_audio_task[f\"{audio_task}_compare_shots\"] = df_all_compare_shots\n",
    "        df_audio_task[f\"{audio_task}_compare_shots_grouped\"] = df_all_compare_shots_grouped\n",
    "\n",
    "print(f\"Saving combined summary to {fn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89c2f0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-ifeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
