{"id": 325, "audio_filepath": "Speech_emotion_recognition/Ses05M_script01_1_M020.wav", "textual_audio": "[00:00:00 - 00:00:03] Oh, so it isn't just my business.(Gender: Male, Emotion: angry)", "instruction": "Listen carefully to the tone, pace, volume, and pitch of the speakers voice, as well as the context and choice of words, to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nWrap your entire response in double angular brackets, such as <<Response>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "angry", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:02] Oh, so it isn't just my business. (Gender: Female, Emotion: Angry).\\nQuestion: Listen carefully to the tone, pace, volume, and pitch of the speakers voice, as well as the context and choice of words, to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nWrap your entire response in double angular brackets, such as <<Response>>\"}]", "response": "<<Based on the given information, the inferred emotional state of the speaker is: \n- Neutral: 0\n- Happy: 0\n- Sad: 0\n- Angry: 1>>", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "<<Based on the given information, the inferred emotional state of the speaker is: \n- Neutral: 0\n- Happy: 0\n- Sad: 0\n- Angry: 1>>", "exact_match": true, "answer_correct": true}
{"id": 326, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro03_F007.wav", "textual_audio": "[00:00:00 - 00:00:04] you met Randy? Oh my god! That's so dramatic! Wasn't it great?(Gender: Female, Emotion: happy)", "instruction": "Listen closely to the tone, pitch, and pace of the speakers voice, and observe any vocal variations, such as sudden rises or falls in confidence, to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEnclose your entire response in double angular brackets, such as <<Answer>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\nQuestion: Listen closely to the tone, pitch, and pace of the speakers voice, and observe any vocal variations, such as sudden rises or falls in confidence, to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEnclose your entire response in double angular brackets, such as <<Answer>>\"}]", "response": "<<I'm not able to access the analysis of the audio file. Please provide the analysis so I can assist you in determining the underlying emotion.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 327, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro07_M036.wav", "textual_audio": "[00:00:00 - 00:00:06] Oh my god, it's awesome. There's going to be tons of places. We're going to have so much fun.(Gender: Male, Emotion: happy)", "instruction": "Listen to the tone, pitch, and pace of the speakers voice, and pay attention to any apparent emphasis on certain words or phrases to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nProvide your reply enclosed within double angular brackets, like <<This is your reply>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:01] Oh, my gosh. (Gender: Male, Emotion: Happy).\\n[00:00:01 - 00:00:03] There's gonna be tons of places. (Gender: Male, Emotion: Happy).\\nQuestion: Listen to the tone, pitch, and pace of the speakers voice, and pay attention to any apparent emphasis on certain words or phrases to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nProvide your reply enclosed within double angular brackets, like <<This is your reply>>\"}]", "response": "<<happy, happy, happy>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 328, "audio_filepath": "Speech_emotion_recognition/Ses05F_script03_2_F004.wav", "textual_audio": "[00:00:00 - 00:00:03] Maybe just a little, but...(Gender: Female, Emotion: neutral)", "instruction": "Pay attention to the tone, pitch, and pace of the speakers voice to identify their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nFormat the entire response in <<double angular brackets>> style", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] a little. (Gender: Female, Emotion: Neutral).\\nQuestion: Pay attention to the tone, pitch, and pace of the speakers voice to identify their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nFormat the entire response in <<double angular brackets>> style\"}]", "response": "<<Based on the given information, the speaker's emotional state at the time range [00:00:01 - 00:00:02] is: neutral.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 329, "audio_filepath": "Speech_emotion_recognition/Ses05F_script01_3_M017.wav", "textual_audio": "[00:00:00 - 00:00:05] Oh, Annie, we're gonna live now. I'm gonna make you so happy.(Gender: Male, Emotion: happy)", "instruction": "Listen to the tone of voice, analyze the pitch, pace, and volume, and consider the context of the spoken words to infer the speaker’s emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nWrite your output and wrap it in <<double angular brackets>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] We're going to live now. (Gender: Male, Emotion: Happy).\\n[00:00:03 - 00:00:05] I'm gonna make you so happy. (Gender: Male, Emotion: Happy).\\nQuestion: Listen to the tone of voice, analyze the pitch, pace, and volume, and consider the context of the spoken words to infer the speaker’s emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nWrite your output and wrap it in <<double angular brackets>>\"}]", "response": "<<\nBased on the given analysis, the speaker's emotional state can be inferred as follows:\n\n- [00:00:01 - 00:00:02]: The speaker's emotional state is Happy.\n- [00:00:03 - 00:00:05]: The speaker's emotional state is Happy.\n>>", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "<<\nBased on the given analysis, the speaker's emotional state can be inferred as follows:\n- [00:00:01 - 00:00:02]: The speaker's emotional state is Happy.\n- [00:00:03 - 00:00:05]: The speaker's emotional state is Happy.\n>>", "exact_match": true, "answer_correct": true}
{"id": 330, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro03_F020.wav", "textual_audio": "[00:00:00 - 00:00:01] 啊(Gender: Female, Emotion: happy)", "instruction": "Pay attention to the tone, pitch, speed, and volume of the speakers voice, as well as any pauses or variations in speech patterns, to infer the emotion being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nRespond using the format <<Your entire message here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\nQuestion: Pay attention to the tone, pitch, speed, and volume of the speakers voice, as well as any pauses or variations in speech patterns, to infer the emotion being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nRespond using the format <<Your entire message here>>\"}]", "response": "I'm ready to analyze the audio file. Please provide the analysis.", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "I'm ready to analyze the audio file. Please provide the analysis.", "exact_match": false, "answer_correct": false}
{"id": 331, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro03_F036.wav", "textual_audio": "[00:00:00 - 00:00:02] That's awesome.(Gender: Female, Emotion: happy)", "instruction": "Listen carefully to the tone, pitch, and pace of the speakers voice, and observe any underlying stress or excitement, as these elements can reveal the speakers emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nSurround your response entirely with <<symbols like this>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\nQuestion: Listen carefully to the tone, pitch, and pace of the speakers voice, and observe any underlying stress or excitement, as these elements can reveal the speakers emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nSurround your response entirely with <<symbols like this>>\"}]", "response": "<<I'm not able to access the specific audio file analysis you provided. However, based on the information you gave me, I can infer that you want me to analyze the detected emotion for each speaker in the audio file. \n\nHowever, since you didn't provide the actual analysis, I'll wait for the information. Please provide the analysis, and I'll be happy to help you with the question.>>", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "<<I'm not able to access the specific audio file analysis you provided. However, based on the information you gave me, I can infer that you want me to analyze the detected emotion for each speaker in the audio file. \nHowever, since you didn't provide the actual analysis, I'll wait for the information. Please provide the analysis, and I'll be happy to help you with the question.>>", "exact_match": true, "answer_correct": true}
{"id": 332, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro02_M011.wav", "textual_audio": "[00:00:00 - 00:00:08] I don't want to... The kids... You gotta take care of them. You gotta...(Gender: Male, Emotion: sad)", "instruction": "Listen carefully to the tone, pitch, and pace of the speakers voice, and observe any contextual clues from their words, to deduce the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEnclose your full response in <<double angular brackets>>, ensuring no part is outside", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:04 - 00:00:05] What? (Gender: Female, Emotion: Happy).\\n[00:00:06 - 00:00:08] you gotta take care of him. You gotta... (Gender: Male, Emotion: Happy).\\nQuestion: Listen carefully to the tone, pitch, and pace of the speakers voice, and observe any contextual clues from their words, to deduce the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEnclose your full response in <<double angular brackets>>, ensuring no part is outside\"}]", "response": "<<The female speaker's tone, pitch, and pace suggest a happy emotion, as indicated by her words \"What?\" which is a question often asked with a positive tone. The male speaker's words \"you gotta take care of him\" also convey a sense of concern and care, which is typically associated with a happy or loving emotion. Therefore, the underlying emotions are: Female - Happy, Male - Happy.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 333, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro02_F029.wav", "textual_audio": "[00:00:00 - 00:00:10] We'll figure something out, we just have to think about this. Could any of your family help us?(Gender: Female, Emotion: sad)", "instruction": "Pay attention to the tone, pitch, and pacing of the speaker’s voice as well as the context of their words to infer their underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nWrap your answer in <<these brackets>> and do not include anything outside them", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:03] something out. We just have to... (Gender: Female, Emotion: Neutral).\\n[00:00:04 - 00:00:05] I have to think about this. (Gender: Female, Emotion: Sad).\\n[00:00:08 - 00:00:10] Could any of your family help us? (Gender: Female, Emotion: Sad).\\nQuestion: Pay attention to the tone, pitch, and pacing of the speaker’s voice as well as the context of their words to infer their underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nWrap your answer in <<these brackets>> and do not include anything outside them\"}]", "response": "<<neutral: [00:00:01 - 00:00:03], happy: none, sad: [00:00:04 - 00:00:05], [00:00:08 - 00:00:10], angry: none>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 334, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro07_M005.wav", "textual_audio": "[00:00:00 - 00:00:01] Yes.(Gender: Female, Emotion: happy)", "instruction": "Listen carefully to the speakers tone, pitch, pace, and volume to identify any emotions conveyed in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nUse <<>> to completely encapsulate your reply, with nothing outside", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:01] Yes. (Gender: Female, Emotion: Happy).\\nQuestion: Listen carefully to the speakers tone, pitch, pace, and volume to identify any emotions conveyed in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nUse <<>> to completely encapsulate your reply, with nothing outside\"}]", "response": "<<happy>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 335, "audio_filepath": "Speech_emotion_recognition/Ses05F_script01_3_M006.wav", "textual_audio": "[00:00:00 - 00:00:02] How did you know?(Gender: Male, Emotion: neutral)", "instruction": "Analyze the tone, pitch, speed, and volume of the spoken words, as well as any changes in these elements, to determine the underlying emotional state being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEnclose the full content of your response in double angular brackets, e.g., <<Complete reply here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] How did you know? (Gender: Male, Emotion: Neutral).\\nQuestion: Analyze the tone, pitch, speed, and volume of the spoken words, as well as any changes in these elements, to determine the underlying emotional state being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEnclose the full content of your response in double angular brackets, e.g., <<Complete reply here>>\"}]", "response": "<<Based on the given information, it is not possible to analyze the tone, pitch, speed, and volume of the spoken words, as well as any changes in these elements, to determine the underlying emotional state being conveyed. However, we can infer the emotional state from the detected emotion, which is Neutral. Therefore, the underlying emotional state being conveyed is Neutral.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 336, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro06_F008.wav", "textual_audio": "[00:00:00 - 00:00:07] Ryan, I know that you're hurting right now, but I don't think you always feel like that.(Gender: Female, Emotion: sad)", "instruction": "Pay attention to the tone, pitch, speed, and volume of the speaker’s voice, as well as any noticeable changes or inconsistencies, to infer the underlying emotion expressed in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nProvide your output wrapped entirely in <<double angular brackets>> for consistency", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:03 - 00:00:04] But... (Gender: Female, Emotion: Sad).\\n[00:00:05 - 00:00:06] Yeah. (Gender: Female, Emotion: Happy).\\nQuestion: Pay attention to the tone, pitch, speed, and volume of the speaker’s voice, as well as any noticeable changes or inconsistencies, to infer the underlying emotion expressed in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nProvide your output wrapped entirely in <<double angular brackets>> for consistency\"}]", "response": "<<neutral, happy, sad, >>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 337, "audio_filepath": "Speech_emotion_recognition/Ses05F_script03_1_M029.wav", "textual_audio": "[00:00:00 - 00:00:04] Oh, that was quite a rouser, wasn't it?(Gender: Male, Emotion: happy)", "instruction": "Listen carefully to the tone, pitch, and speed of the speakers voice to determine their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nFrame your response entirely within <<double angular brackets>>, like this: <<Example>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:01] Oh. (Gender: Female, Emotion: Happy).\\n[00:00:02 - 00:00:04] That was quite a rouser, wasn't it? (Gender: Male, Emotion: Happy).\\nQuestion: Listen carefully to the tone, pitch, and speed of the speakers voice to determine their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nFrame your response entirely within <<double angular brackets>>, like this: <<Example>>\"}]", "response": "<<Happy, Happy, Neutral>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 338, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro02_F035.wav", "textual_audio": "[00:00:00 - 00:00:04] Three weeks.(Gender: Female, Emotion: sad)", "instruction": "Analyze the tone, pitch, pace, and facial expressions accompanying the spoken words to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nPlace your full reply inside <<these brackets>> and ensure no content is outside them", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:03 - 00:00:04] Three weeks. (Gender: Female, Emotion: Sad).\\nQuestion: Analyze the tone, pitch, pace, and facial expressions accompanying the spoken words to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nPlace your full reply inside <<these brackets>> and ensure no content is outside them\"}]", "response": "<<Based on the given information, the underlying emotion is Sad, as indicated by the detected emotion. The tone, pitch, pace, and facial expressions are not explicitly mentioned, but the detected emotion provides a clear indication of the speaker's emotional state.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 339, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro01_F000.wav", "textual_audio": "[00:00:00 - 00:00:03] Hi, I need an ID.(Gender: Female, Emotion: neutral)", "instruction": "Pay close attention to the tone, pitch, and pace of the speakers voice, as well as any noticeable inflections or pauses, to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEncapsulate your response within double angular brackets, e.g., <<Content goes here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] I need an ID. (Gender: Female, Emotion: Neutral).\\nQuestion: Pay close attention to the tone, pitch, and pace of the speakers voice, as well as any noticeable inflections or pauses, to infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEncapsulate your response within double angular brackets, e.g., <<Content goes here>>\"}]", "response": "<<neutral>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 340, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro08_F016.wav", "textual_audio": "[00:00:00 - 00:00:01] Okay.(Gender: Female, Emotion: neutral)", "instruction": "Listen carefully to the tone, pitch, speed, and volume of the persons voice to determine if they sound happy, sad, angry, surprised, fearful, disgusted, or neutral. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEnsure the entire response is enclosed in <<>> with no extra characters outside", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:01] Okay. Okay. (Gender: Female, Emotion: Neutral).\\nQuestion: Listen carefully to the tone, pitch, speed, and volume of the persons voice to determine if they sound happy, sad, angry, surprised, fearful, disgusted, or neutral. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEnsure the entire response is enclosed in <<>> with no extra characters outside\"}]", "response": "<<neutral>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 341, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro03_M025.wav", "textual_audio": "[00:00:00 - 00:00:08] Oh yeah, my mom's freaking out. Oh yeah, she's so happy. This is, you know, it's her dream come true. She always wants her little boy. She wants kids, you know.(Gender: Male, Emotion: happy)", "instruction": "Listen to the tone, pitch, and pace of the speakers voice, as well as any pauses or hesitations, to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nWrap everything you write in <<double angular brackets>> for uniform formatting", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:02] Oh yeah, my mom's freaking out. (Gender: Male, Emotion: Happy).\\n[00:00:03 - 00:00:08] Yeah, she's so happy. You know, it's her dream come true. She always wanted her little boy. She wants kids, you know. (Gender: Male, Emotion: Happy).\\nQuestion: Listen to the tone, pitch, and pace of the speakers voice, as well as any pauses or hesitations, to determine the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nWrap everything you write in <<double angular brackets>> for uniform formatting\"}]", "response": "<<Based on the provided analysis, the speaker's emotions can be categorized as follows:>>\n\n- [00:00:00 - 00:00:02]: happy\n- [00:00:03 - 00:00:08]: happy", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "- [00:00:00 - 00:00:02]: happy\n- [00:00:03 - 00:00:08]: happy", "exact_match": true, "answer_correct": true}
{"id": 342, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro02_F011.wav", "textual_audio": "[00:00:00 - 00:00:02] Iraq.(Gender: Female, Emotion: happy)", "instruction": "Pay attention to the tone, pace, volume, and pitch of the speakers voice, as these vocal cues often reveal underlying emotions more clearly than the actual words being spoken. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nUse double angular brackets, like <<this>>, to wrap your entire reply", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:01] Iraq. (Gender: Female, Emotion: Happy).\\nQuestion: Pay attention to the tone, pace, volume, and pitch of the speakers voice, as these vocal cues often reveal underlying emotions more clearly than the actual words being spoken. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nUse double angular brackets, like <<this>>, to wrap your entire reply\"}]", "response": "<<Based on the given information, it is not possible to determine the tone, pace, volume, and pitch of the speaker's voice. However, we can infer the emotion from the provided information. \n\nThe detected emotion for the given time range is: Happy.>>", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "<<Based on the given information, it is not possible to determine the tone, pace, volume, and pitch of the speaker's voice. However, we can infer the emotion from the provided information. \nThe detected emotion for the given time range is: Happy.>>", "exact_match": false, "answer_correct": false}
{"id": 343, "audio_filepath": "Speech_emotion_recognition/Ses05M_impro06_M000.wav", "textual_audio": "[00:00:00 - 00:00:04] I just got some bad news.(Gender: Male, Emotion: sad)", "instruction": "Listen carefully to the tone, pitch, pace, and volume of the spoken utterance, and pay attention to the choice of words and context to infer the speakers emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nRespond fully encapsulated in <<double angular brackets>>, e.g., <<This is the format>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "sad", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:02 - 00:00:03] got some bad news. (Gender: Male, Emotion: Sad).\\nQuestion: Listen carefully to the tone, pitch, pace, and volume of the spoken utterance, and pay attention to the choice of words and context to infer the speakers emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nRespond fully encapsulated in <<double angular brackets>>, e.g., <<This is the format>>\"}]", "response": "<<The speaker's emotion is sad, as inferred from the transcribed speech \"got some bad news\" and the detected emotion \"Sad\".>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 344, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro04_M015.wav", "textual_audio": "[00:00:00 - 00:00:07] I mean if it's rent or something like that I can help you out a little bit if that will help you stick with it(Gender: Male, Emotion: neutral)", "instruction": "Listen closely to the tone, pace, volume, and pitch variations of the speaker’s voice to determine their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nEnclose all parts of your response in <<double angular brackets>>, such as <<Response here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:04] it's rent or something like that, I mean, I can help you out a little bit if (Gender: Male, Emotion: Neutral).\\n[00:00:04 - 00:00:06] if that'll help you stick with it (Gender: Male, Emotion: Neutral).\\nQuestion: Listen closely to the tone, pace, volume, and pitch variations of the speaker’s voice to determine their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nEnclose all parts of your response in <<double angular brackets>>, such as <<Response here>>\"}]", "response": "<<Based on the provided audio analysis, the speaker's emotional state can be categorized as follows: \n\n- Neutral: [00:00:01 - 00:00:04] (Neutral emotion is explicitly mentioned), [00:00:04 - 00:00:06] (Neutral emotion is explicitly mentioned)\n- Happy: None\n- Sad: None\n- Angry: None>>", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "<<Based on the provided audio analysis, the speaker's emotional state can be categorized as follows: \n- Neutral: [00:00:01 - 00:00:04] (Neutral emotion is explicitly mentioned), [00:00:04 - 00:00:06] (Neutral emotion is explicitly mentioned)\n- Happy: None\n- Sad: None\n- Angry: None>>", "exact_match": false, "answer_correct": false}
{"id": 345, "audio_filepath": "Speech_emotion_recognition/Ses05F_script03_2_F012.wav", "textual_audio": "[00:00:00 - 00:00:02] It's becoming a habit with you.(Gender: Female, Emotion: neutral)", "instruction": "Listen carefully to the tone, pitch, and pace of the speakers voice in order to identify the underlying emotion being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nDeliver your answer using the format <<entire response goes here>> with no exceptions", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] a habit with you. (Gender: Female, Emotion: Neutral).\\nQuestion: Listen carefully to the tone, pitch, and pace of the speakers voice in order to identify the underlying emotion being conveyed. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nDeliver your answer using the format <<entire response goes here>> with no exceptions\"}]", "response": "Based on the given information, the underlying emotion being conveyed by the speaker is Neutral.", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "Based on the given information, the underlying emotion being conveyed by the speaker is Neutral.", "exact_match": true, "answer_correct": true}
{"id": 346, "audio_filepath": "Speech_emotion_recognition/Ses05M_script02_2_M036.wav", "textual_audio": "[00:00:00 - 00:00:04] Oh, look what we got here.(Gender: Male, Emotion: happy)", "instruction": "Listen to the tone, pitch fluctuations, speech rate, and volume to determine the underlying emotion in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nReply fully enclosed within <<double angular brackets>> for clarity, e.g., <<Answer here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] Look what we got. (Gender: Male, Emotion: Happy).\\nQuestion: Listen to the tone, pitch fluctuations, speech rate, and volume to determine the underlying emotion in the spoken utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nReply fully enclosed within <<double angular brackets>> for clarity, e.g., <<Answer here>>\"}]", "response": "<<happy>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 347, "audio_filepath": "Speech_emotion_recognition/Ses05F_script01_1_M013.wav", "textual_audio": "[00:00:00 - 00:00:07] gonna do? For God's sake, Mom. Three years. Nobody comes back after three years. It's insane. To you, it isn't.(Gender: Female, Emotion: angry)", "instruction": "Listen to the tone, pitch, and pacing of the speakers voice, paying close attention to any variations, and consider the context and words used to infer the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nCompletely wrap your response in <<brackets like this>>, ensuring no text is outside", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "angry", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:01 - 00:00:02] sake, Mom. (Gender: Male, Emotion: Happy).\\n[00:00:02 - 00:00:06] Three years. Nobody comes back after three years. It's insane. (Gender: Female, Emotion: Angry).\\nQuestion: Listen to the tone, pitch, and pacing of the speakers voice, paying close attention to any variations, and consider the context and words used to infer the underlying emotion. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nCompletely wrap your response in <<brackets like this>>, ensuring no text is outside\"}]", "response": "[Neutral: None, Happy: Male (00:00:01 - 00:00:02), Sad: None, Angry: Female (00:00:02 - 00:00:06)]", "follow_instruction_list": [false], "follow_all_instructions": false, "strict_follow_instruction_list": [false], "strict_follow_all_instructions": false, "loose_follow_instruction_list": [false], "loose_follow_all_instructions": false, "response_for_scoring": "[Neutral: None, Happy: Male (00:00:01 - 00:00:02), Sad: None, Angry: Female (00:00:02 - 00:00:06)]", "exact_match": true, "answer_correct": true}
{"id": 348, "audio_filepath": "Speech_emotion_recognition/Ses05M_script03_1_M026.wav", "textual_audio": "[00:00:00 - 00:00:04] The one where you bought that little painted wooden stake and you put it on my bed? Uh-huh.(Gender: Male, Emotion: happy)", "instruction": "Pay attention to the tone, pitch, speed, and volume of the speakers voice to infer the underlying emotion in the utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nFormat the full response using <<double angular brackets>> style, e.g., <<Reply here>>", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "happy", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:04] The one where you bought that little painted wooden stake and you put it on my bed? (Gender: Male, Emotion: Happy).\\nQuestion: Pay attention to the tone, pitch, speed, and volume of the speakers voice to infer the underlying emotion in the utterance. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nFormat the full response using <<double angular brackets>> style, e.g., <<Reply here>>\"}]", "response": "<<Based on the given information, it can be inferred that the underlying emotion in the utterance is happy, as the detected emotion is Happy and the speaker's tone, pitch, speed, and volume are not explicitly mentioned, but the context suggests a positive and cheerful tone.>>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
{"id": 349, "audio_filepath": "Speech_emotion_recognition/Ses05F_impro05_M022.wav", "textual_audio": "[00:00:00 - 00:00:07] Well, let's just relax for a moment, ma'am. You understand, obviously, we're going to do everything we can to keep all of your luggage here.(Gender: Male, Emotion: neutral)", "instruction": "Pay close attention to the tone, pitch, and pace of the speakers voice, as well as their choice of words and context, to accurately infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\nProvide your reply entirely enclosed in <<>> without adding anything outside them", "dataset": "Speech_emotion_recognition", "metric": "accuracy", "instruction_id_list": ["detectable_format:title"], "kwargs": [{}], "label": "neutral", "messages": "[{\"role\": \"system\", \"content\": \"You are a helpful voice assistant. You will be provided with 0 example pairs of questions and answers based on audio inputs. You should follow the examples to answer the last question.\"}, {\"role\": \"user\", \"content\": \"Below is an analysis of an audio file. \\nEach line contains: a time range, the transcribed speech, the speaker's perceived gender, the detected emotion \\n Please use this information to answer the question. Only answer what is explicitly asked.\\n[00:00:00 - 00:00:06] Well, let's just relax for a moment, ma'am. You understand, obviously, we're going to do everything we can to keep all of your luggage here. (Gender: Male, Emotion: Neutral).\\nQuestion: Pay close attention to the tone, pitch, and pace of the speakers voice, as well as their choice of words and context, to accurately infer their emotional state. Please answer with the following four emotion categories: neutral, happy, sad, and angry.\\nProvide your reply entirely enclosed in <<>> without adding anything outside them\"}]", "response": "<< Neutral >>", "follow_instruction_list": [true], "follow_all_instructions": true, "strict_follow_instruction_list": [true], "strict_follow_all_instructions": true, "loose_follow_instruction_list": [true], "loose_follow_all_instructions": true, "response_for_scoring": "", "exact_match": false, "answer_correct": false}
