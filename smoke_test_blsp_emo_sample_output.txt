[BLSP-emo] Initializing model ... [BLSP-emo] Loading model from: blsp_emo_weights
INFO:models.blsp_emo_package.src.configuration_blsp2:whisper config is None. Initializing the WhisperConfig with defau
lt values
INFO:models.blsp_emo_package.src.configuration_blsp2:qwen config is None. Initializing the QwenConfig with default val
ues   
WARNING:models.blsp_emo_package.src.modeling_qwen:Warning: please make sure that you are using the latest codes and ch
eckpoints, especially if you used Qwen-7B before 09.25.2023.请使用最新模型和代码，尤其如果你在9月25日前已经开始使用Qwe
n-7B， 千万注意不要使用错误代码和模型。
WARNING:models.blsp_emo_package.src.modeling_qwen:The model is automatically converting to bf16 for faster inference. 
If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_
pretrained".
Loading checkpoint shards: 100%|█| 2/2 [
[BLSP-emo] Model loaded with actual dtype: torch.float16
Done! Model initialized in 339.35 seconds.

--- Running Test Case 1 ---
=== Testing BLSP-emo ===
blsp-emo/lib/python3.11/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_res
ources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package
 is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import resource_filename
[BLSP-emo] Processing input ... Done! Input processed in 0.85 seconds.
blsp-emo/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:36
7: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-ba
sed generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
blsp-emo/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:37
7: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-base
d generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
[BLSP-emo] Generating output ... Done! Output generated in 0.91 seconds.

[BLSP-emo] Output: The emotion tone of the speech is happy.

--- Running Test Case 2 ---
=== Testing BLSP-emo ===
[BLSP-emo] Processing input ... Done! Input processed in 0.04 seconds.
blsp-emo/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
blsp-emo/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
[BLSP-emo] Generating output ... Done! Output generated in 0.89 seconds.

[BLSP-emo] Output: The speaker is asking which sport was the most watched during the last summer Olympics.

--- Running Test Case 3 ---
=== Testing BLSP-emo ===
[BLSP-emo] Processing input ... Done! Input processed in 0.03 seconds.
[BLSP-emo] Generating output ... Done! Output generated in 0.85 seconds.

[BLSP-emo] Output: The speaker in the audio says, "When was oil discovered in Venezuela?"

--- Running Test Case 4 ---
=== Testing BLSP-emo ===
[BLSP-emo] Processing input ... Done! Input processed in 0.00 seconds.
[BLSP-emo] Generating output ... Done! Output generated in 0.94 seconds.

[BLSP-emo] Output: I am a large language model created by Alibaba Cloud. I am called QianWen.